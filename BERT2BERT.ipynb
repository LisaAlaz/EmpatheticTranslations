{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtsIdO2bpygp"
      },
      "source": [
        "#3. BERT2BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAWvNDvh8ekJ"
      },
      "source": [
        "This model is composed of a BERT encoder and a BERT decoder, initialised with pre-trained embeddings from BERT base uncased. The attention layer is initialised randomly. This model has 247,363,386 tunable parameters and overfits the data quickly, so we use a very small learning rate of 0.000001 and train it for only ten epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHxbWmnrSQI"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRa5-KdWrBmS"
      },
      "source": [
        "#import statements\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizerFast , BertTokenizer\n",
        "from transformers import BertModel, BertForMaskedLM, BertConfig, EncoderDecoderModel , BertLMHeadModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maLOpQLW7Mk2"
      },
      "source": [
        "##3a) Non-empathetic response as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ6gqJP_px3r"
      },
      "source": [
        "#import csv into dataframe\n",
        "data_df = pd.read_csv('drive/MyDrive/data.csv', encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKs4E-gp7BV5"
      },
      "source": [
        "train_df = data_df.iloc[: int(len(data_df) * 0.8 ) ,:  ]\n",
        "val_df_copy = data_df.iloc[ len(data_df) - int(len(data_df) * 0.2 ) :  ,:  ]\n",
        "val_df = val_df_copy.iloc[ int( len(val_df_copy) * 0.5 ) : , :  ]\n",
        "test_df = val_df_copy.iloc[ : int( len(val_df_copy) * 0.5 ) , :  ]\n",
        "\n",
        "train_df.to_csv( \"train_data.csv\" )\n",
        "val_df.to_csv( \"val_data.csv\" )\n",
        "test_df.to_csv( \"test_data.csv\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWu9VCBgqwB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deaa8a25-c467-4c2f-b5a8-e6554af8b992"
      },
      "source": [
        "for i_row in data_df.iterrows():\n",
        "  print(i_row[1].source)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Been in a similar situation after taking some time off of school. My best advice is to take the minimum amount of classes possible so you get too overwhelmed. For me essential to plan my assignments in advance, so that I can just do things one by one and not let it all get piled up cuz then I wanna die. Also, if you need a break, take one. School will always be there but good to take care of yourself too  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROKmAMyYq0en"
      },
      "source": [
        "def convert_text( en_file , en_comp_file , data_df  ):\n",
        "  with open( en_file , \"w\") as my_output_file:\n",
        "    [ my_output_file.write(\"\".join(row[1].source)+'\\n') for row in  data_df.iterrows() ]\n",
        "    my_output_file.close()\n",
        "\n",
        "  with open( en_comp_file , \"w\") as my_output_file:\n",
        "    [ my_output_file.write(\"\".join(row[1].target)+'\\n') for row in  data_df.iterrows() ]\n",
        "    my_output_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxaQYkvUq7ET"
      },
      "source": [
        "train_en_file = 'train_en.txt' \n",
        "train_en_comp_file = \"train_en_comp.txt\"\n",
        "convert_text( train_en_file , train_en_comp_file , train_df )\n",
        "\n",
        "val_en_file = 'val_en.txt' \n",
        "val_en_comp_file = \"val_en_comp.txt\"\n",
        "convert_text( val_en_file , val_en_comp_file , val_df )\n",
        "\n",
        "test_en_file = 'test_en.txt' \n",
        "test_en_comp_file = \"test_en_comp.txt\"\n",
        "convert_text( test_en_file , test_en_comp_file , test_df )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ctODdbBrHS0"
      },
      "source": [
        "globalparams ={\n",
        "        \"train_en_file\" : \"/content/train_en.txt\",\n",
        "        \"train_en_comp_file\" : \"/content/train_en_comp.txt\",\n",
        "        \"val_en_file\":\"/content/val_en.txt\" , \n",
        "        \"val_en_comp_file\":\"/content/val_en_comp.txt\",\n",
        "        \"test_en_file\":\"/content/test_en.txt\" , \n",
        "        \"test_en_comp_file\":\"/content/test_en_comp.txt\"}\n",
        "\n",
        "encparams = {\n",
        "        \"tokenizer_path\" : \"tokenizers/\",\n",
        "        \"file_name\" : \"en.text\",\n",
        "        \"min_freq\" : 0 ,\n",
        "        \"max_length\" : 512,\n",
        "        \"num_attn_heads\" : 8,\n",
        "        \"num_hidden_layers\" : 8,\n",
        "        \"hidden_size\" : 512 }\n",
        "\n",
        "decparams = {\n",
        "        \"tokenizer_path\" : \"tokenizers/\",\n",
        "        \"file_name\" : \"en_comp.text\",\n",
        "        \"min_freq\" : 0 ,\n",
        "        \"max_length\" : 256,\n",
        "        \"num_attn_heads\" : 8,\n",
        "        \"num_hidden_layers\" : 8,\n",
        "        \"hidden_size\" : 512}\n",
        "\n",
        "modelparams = {\n",
        "        \"batch_size\" : 4 ,\n",
        "        \"num_epochs\" : 1,\n",
        "        \"lr\": 0.000001,\n",
        "        \"model_path\" : \"models/\",\n",
        "        \"model_name\": \"encdec.mdl\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OGWDcEcrNLW"
      },
      "source": [
        "tokenizer.cls_token = \"[CLS]\"\n",
        "tokenizer.unk_token = \"[UNK]\"\n",
        "tokenizer.sep_token = \"[SEP]\"\n",
        "tokenizer.pad_token = \"[PAD]\" \n",
        "tokenizer.bos_token = \"[S]\"\n",
        "tokenizer.mask_token = \"[MASK]\"\n",
        "tokenizer.eos_token =  \"[/S]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfGX3tb0rZZx"
      },
      "source": [
        "tokenizer.do_lower_case = True\n",
        "\n",
        "tokenizer._tokenizer.post_processor = BertProcessing((\"[SEP]\", tokenizer.bos_token_id  ), \n",
        "                                                     (\"[CLS]\", tokenizer.cls_token_id   ),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0LNsm5HraZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763602bf-4c3c-4bae-d2f7-04c4741fd688"
      },
      "source": [
        "len( tokenizer.get_vocab() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ys_XQSzsbBj"
      },
      "source": [
        "class TranslationDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, inp_file, targ_file, inp_tokenizer, targ_tokenizer, inp_maxlength, targ_maxlength):\n",
        "\n",
        "        self.inp_tokenizer = inp_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.inp_maxlength = inp_maxlength\n",
        "        self.targ_maxlength = targ_maxlength\n",
        "\n",
        "        print(\"Loading and Tokenizing the data ...\")\n",
        "        self.encoded_inp = []\n",
        "        self.encoded_targ = []\n",
        "\n",
        "        # Read the source lines\n",
        "        num_inp_lines = 0\n",
        "        with open(inp_file, \"r\") as ef:\n",
        "            for line in ef:\n",
        "                enc = self.inp_tokenizer.encode(line.strip(), add_special_tokens=True, max_length=self.inp_maxlength , truncation=True)\n",
        "                self.encoded_inp.append(torch.tensor(enc))\n",
        "                num_inp_lines += 1\n",
        "\n",
        "        # read the target lines\n",
        "        num_targ_lines = 0\n",
        "        with open(targ_file, \"r\") as df:\n",
        "            for line in df:\n",
        "                enc = self.targ_tokenizer.encode(line.strip(), add_special_tokens=True, max_length=self.targ_maxlength , truncation=True)\n",
        "                self.encoded_targ.append(torch.tensor(enc))\n",
        "                num_targ_lines += 1\n",
        "\n",
        "        assert (num_inp_lines==num_targ_lines), \"Mismatch in source and target lines\"\n",
        "        print(\"Read\", num_inp_lines, \"lines from source and target files.\")\n",
        "\n",
        "    def __getitem__(self, offset):\n",
        "        src = self.encoded_inp[offset]\n",
        "        trg = self.encoded_targ[offset]\n",
        "\n",
        "        return src, src.shape[0], trg, trg.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_inp)\n",
        "\n",
        "    def collate_function(self, batch):\n",
        "\n",
        "        (inputs, inp_lengths, targets, targ_lengths) = zip(*batch)\n",
        "\n",
        "        padded_inputs = self._collate_helper(inputs, self.inp_tokenizer)\n",
        "        padded_targets = self._collate_helper(targets, self.targ_tokenizer)\n",
        "\n",
        "        max_inp_seq_len = padded_inputs.shape[1]\n",
        "        max_out_seq_len = padded_targets.shape[1]\n",
        "\n",
        "        input_masks = [[1]*l + [0]*(max_inp_seq_len-l) for l in inp_lengths]\n",
        "        target_masks = [[1]*l + [0]*(max_out_seq_len-l) for l in targ_lengths]\n",
        "\n",
        "        input_tensor = padded_inputs.to(torch.int64)\n",
        "        target_tensor = padded_targets.to(torch.int64)\n",
        "        input_masks = torch.Tensor(input_masks)\n",
        "        target_masks = torch.Tensor(target_masks)\n",
        "\n",
        "        return input_tensor, input_masks, target_tensor, target_masks\n",
        "\n",
        "    def _collate_helper(self, examples, tokenizer):\n",
        "        length_of_first = examples[0].size(0)\n",
        "        are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
        "        if are_tensors_same_length:\n",
        "            return torch.stack(examples, dim=0)\n",
        "        else:\n",
        "            if tokenizer._pad_token is None:\n",
        "                raise ValueError(\n",
        "                    \"You are attempting to pad samples but the tokenizer you are using\"\n",
        "                    f\" ({tokenizer.__class__.__name__}) does not have one.\"\n",
        "                )\n",
        "            return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmho76R5tEEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5364fe1a-f3a3-4a7b-d7bf-0f8307b90938"
      },
      "source": [
        "# Load the tokenizers\n",
        "en_tokenizer = tokenizer\n",
        "en_complex_tokenizer = tokenizer\n",
        "\n",
        "# Init the dataset\n",
        "train_en_file = globalparams[\"train_en_file\"]\n",
        "train_en_complex_file = globalparams[\"train_en_comp_file\"]\n",
        "val_en_file = globalparams[\"val_en_file\"]\n",
        "val_en_complex_file = globalparams[\"val_en_comp_file\"]\n",
        "test_en_file = globalparams[\"test_en_file\"]\n",
        "test_en_complex_file = globalparams[\"test_en_comp_file\"]\n",
        "\n",
        "enc_maxlength = encparams[\"max_length\"]\n",
        "dec_maxlength = decparams[\"max_length\"]\n",
        "\n",
        "batch_size = modelparams[\"batch_size\"]\n",
        "\n",
        "train_dataset = TranslationDataset( train_en_file, train_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=train_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 986 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8eYWYJetZGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fd3df9-f915-48be-ba61-9e9d98fe0744"
      },
      "source": [
        "valid_dataset = TranslationDataset(val_en_file, val_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=valid_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 123 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gdKKNDKxLSt",
        "outputId": "f03d371a-92b6-42ba-dfef-da36b2676360"
      },
      "source": [
        "test_dataset = TranslationDataset(test_en_file, test_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=test_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 123 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHyjcC_2tcwP"
      },
      "source": [
        "x , _ , y , _ = next(iter(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VbEW9artfps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd298ef-c6f6-4ad8-ed44-0f49117b92c5"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bquqxjxJtiw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "5b5e5e5a3ac34721a256c4ad224dd94e",
            "32f9ca165751416eabc2210f1a4bd969",
            "17fe4b5ec48341a9b19078d45892d019",
            "b5025824c3ef464c94ba00e73c295eef",
            "b0f01fb07cd947c783d8c09f5590a165",
            "5cad2b966d6a4a0db8c4944c166b1f1b",
            "17c38faa325b4cf89dc4fdd34af7dc81",
            "78786998ad1e4e6b900f19be3435bd16",
            "76ad22d5130347a0bbdf8cc0bd5905e1",
            "f2c437dc78a741ed8e3c1f9f2dd19980",
            "ce7bc726e3f34b739baec00735ac6e2a",
            "95918d15c20d43e28c20504679f20c7e",
            "51363b897bee4b3782e35a4ab6c4deae",
            "21e3c0daf25845c0b17c6141848ca893",
            "a7b5ec4faa35465ca2a68042c146934b",
            "0ccf2589049543b5aa2515a1173f3ea8"
          ]
        },
        "outputId": "fe64c390-0f84-497b-b1c2-d094528cbdee"
      },
      "source": [
        "bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b5e5e5a3ac34721a256c4ad224dd94e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ad22d5130347a0bbdf8cc0bd5905e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xme9h5ZALQ2h"
      },
      "source": [
        "bert2bert.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "bert2bert.config.eos_token_id = tokenizer.sep_token_id\n",
        "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
        "bert2bert.config.vocab_size = bert2bert.config.encoder.vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtHb6JmLLSPP"
      },
      "source": [
        "bert2bert.config.max_length = 120\n",
        "bert2bert.config.min_length = 56\n",
        "bert2bert.config.no_repeat_ngram_size = 2\n",
        "bert2bert.config.early_stopping = True\n",
        "bert2bert.config.length_penalty = 2.0\n",
        "bert2bert.config.num_beams = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmhMCwr-tjod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657bc65b-aae0-43f5-f2e9-fea3ba69ad9b"
      },
      "source": [
        "bert2bert.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoderModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE8OtkTJtqhM"
      },
      "source": [
        "#define optimiser and loss function\n",
        "optimizer = optim.Adam( bert2bert.parameters(), lr=modelparams['lr'])\n",
        "criterion = nn.CrossEntropyLoss(ignore_index= tokenizer.pad_token_id)\n",
        "\n",
        "num_train_batches = len(train_dataloader)\n",
        "num_valid_batches = len(valid_dataloader)\n",
        "num_test_batches = len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhc7YkJgttQo"
      },
      "source": [
        "def compute_loss(predictions, targets):\n",
        "    \"\"\"Compute our custom loss\"\"\"\n",
        "    predictions = predictions[:, :-1, :].contiguous()\n",
        "    targets = targets[:, 1:]\n",
        "\n",
        "    rearranged_output = predictions.view(predictions.shape[0]*predictions.shape[1], -1)\n",
        "    rearranged_target = targets.contiguous().view(-1)\n",
        "\n",
        "    loss = criterion(rearranged_output, rearranged_target)\n",
        "\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4XPPmmgtufL"
      },
      "source": [
        "tr = {'loss': [], 'PPL': []}\n",
        "\n",
        "def train_model():\n",
        "    bert2bert.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(train_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert2bert.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    train_loss = epoch_loss / num_train_batches\n",
        "\n",
        "    # store logs\n",
        "    tr['loss'].append(train_loss)\n",
        "    tr['PPL'].append(math.exp(train_loss))\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqAx5Y1RtyAO"
      },
      "source": [
        "val = {'loss': [], 'PPL': []}\n",
        "\n",
        "def eval_model():\n",
        "    bert2bert.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(valid_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    valid_loss =  epoch_loss / num_valid_batches \n",
        "\n",
        "    # store logs\n",
        "    val['loss'].append(valid_loss)\n",
        "    val['PPL'].append(math.exp(valid_loss))\n",
        "\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJo38so1Ehw"
      },
      "source": [
        "tst = {'loss': [], 'PPL': []}\n",
        "\n",
        "def test_model():\n",
        "    bert2bert.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(test_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    test_loss =  epoch_loss / num_valid_batches \n",
        "\n",
        "    # store logs\n",
        "    tst['loss'].append(test_loss)\n",
        "    tst['PPL'].append(math.exp(test_loss))\n",
        "\n",
        "    print(f'\\t Test Loss: {test_loss:.3f} |  Test PPL: {math.exp(test_loss):7.3f}')\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nKvRTjlpT8X",
        "outputId": "9be99c8e-5509-4025-cbc5-6d22615c6429"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(bert2bert):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 247,363,386 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp1slyKft5_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6dadcc9-d410-4426-946b-dea68cb8218b"
      },
      "source": [
        "# MAIN TRAINING LOOP\n",
        "for epoch in range(10):\n",
        "    print(\"Starting epoch\", epoch+1)\n",
        "    train_model()\n",
        "    eval_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "\tTrain Loss: 6.585 | Train PPL: 724.265\n",
            "\t Val. Loss: 5.968 |  Val. PPL: 390.677\n",
            "Starting epoch 2\n",
            "\tTrain Loss: 5.835 | Train PPL: 342.229\n",
            "\t Val. Loss: 5.541 |  Val. PPL: 255.034\n",
            "Starting epoch 3\n",
            "\tTrain Loss: 5.516 | Train PPL: 248.607\n",
            "\t Val. Loss: 5.240 |  Val. PPL: 188.727\n",
            "Starting epoch 4\n",
            "\tTrain Loss: 5.276 | Train PPL: 195.557\n",
            "\t Val. Loss: 5.043 |  Val. PPL: 154.887\n",
            "Starting epoch 5\n",
            "\tTrain Loss: 5.108 | Train PPL: 165.285\n",
            "\t Val. Loss: 4.911 |  Val. PPL: 135.800\n",
            "Starting epoch 6\n",
            "\tTrain Loss: 4.983 | Train PPL: 145.870\n",
            "\t Val. Loss: 4.815 |  Val. PPL: 123.339\n",
            "Starting epoch 7\n",
            "\tTrain Loss: 4.886 | Train PPL: 132.373\n",
            "\t Val. Loss: 4.739 |  Val. PPL: 114.312\n",
            "Starting epoch 8\n",
            "\tTrain Loss: 4.800 | Train PPL: 121.549\n",
            "\t Val. Loss: 4.678 |  Val. PPL: 107.516\n",
            "Starting epoch 9\n",
            "\tTrain Loss: 4.726 | Train PPL: 112.799\n",
            "\t Val. Loss: 4.628 |  Val. PPL: 102.352\n",
            "Starting epoch 10\n",
            "\tTrain Loss: 4.654 | Train PPL: 105.007\n",
            "\t Val. Loss: 4.584 |  Val. PPL:  97.878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "Vr2EfAZIZa_1",
        "outputId": "2925875d-643a-403e-dcf7-35b5b710584c"
      },
      "source": [
        "#plot train and validation PPL logs\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "y1 = tr['PPL']\n",
        "y2 = val['PPL']\n",
        "\n",
        "plt.plot(y1, \"-b\", label=\"Train perplexity\")\n",
        "plt.plot(y2, \"-r\", label=\"Validation perplexity\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.ylim(0, 800)\n",
        "plt.ylabel('Perplexity', fontsize=12)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.title(\"Train and validation perplexity \\n BERT2BERT - Non-empathetic response input\", fontsize = 14)\n",
        "\n",
        "fig.savefig(\"3a-ppl.pdf\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNTtN9l_yNZ1",
        "outputId": "123ab8f2-a702-4abd-8246-95f58a4a12fa"
      },
      "source": [
        "test_loss_3a = test_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Test Loss: 4.478 |  Test PPL:  88.056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGLu5J42uA8d"
      },
      "source": [
        "print(\"Saving model ..\")\n",
        "save_location = modelparams['model_path']\n",
        "model_name = modelparams['model_name']\n",
        "if not os.path.exists(save_location):\n",
        "    os.makedirs(save_location)\n",
        "save_location = os.path.join(save_location, model_name)\n",
        "torch.save(bert2bert, save_location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k72BbBWb0Hf3"
      },
      "source": [
        "def generate_sentence(model, iterator):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    pred_trg_pairs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, (en_input, en_masks, de_output, de_masks) in enumerate(iterator):\n",
        "\n",
        "            en_input = en_input.to(device)\n",
        "            de_output = de_output.to(device)\n",
        "            en_masks = en_masks.to(device)\n",
        "            de_masks = de_masks.to(device)\n",
        "\n",
        "            lm_labels = de_output.clone()\n",
        "\n",
        "            out = model(input_ids=en_input, attention_mask=en_masks,\n",
        "                                            decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "            prediction_scores = out[1]\n",
        "            outputs = torch.argmax( prediction_scores , dim = -1 )\n",
        "            output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "            target_str = tokenizer.batch_decode( de_output , skip_special_tokens=True)\n",
        "\n",
        "            for i_pred , i_trg in zip( output_str , target_str  ):\n",
        "\n",
        "              print( \"Target Sentence : {} \\n\".format( i_trg )  )\n",
        "              print( \"Predicted Sentence : {} \\n\".format( i_pred )  )\n",
        "            \n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJFnlVrb0ImN",
        "outputId": "8632dacc-b804-46b9-854c-e7cd47c3c261"
      },
      "source": [
        "generate_sentence( bert2bert , test_dataloader )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence : i think that avoiding work to sit at home in your misery is a bad thing. getting out of the house is recommended even if it's something like going to work. obviously do whatever you feel is best but i don't think skipping work is going to help you get any better. for example i could barely get out of bed this morning to go to work but even though i'm here hating it i would alternatively be at home sleeping until 2pm then lay in bed on my phone all day. \n",
            "\n",
            "Predicted Sentence : i'i i you. try. at. my head. a bad thing. i better of the world. a to if i is s not to that on get. i i have i want like going to i'' t know it.. going to try me. out job job i you if'try get to of the. way. try out sleep. i if i'm trying to myself,'really try able the. out i.. i out the. the bed...'' just a doing've just a least home sleep sleep the... i the bed bed. i i i my the the the the the a. if is.. just'just trying least the sleep sleep sleep out the the the.. a bad hard. i a my the my i a not better better's better hard just hard my try sleep sleep sleep sleep sleep the the the.. head way bad bad hard thing job a a the the work way hard hard hard better better better better hard hard hard hard do get get the the. head i not hard. \n",
            "\n",
            "Target Sentence : it is unfair. modern psychology / psychiatry is completely incapable of helping those who are in severe pain with lifelong battles with mental illness. it often feels like we are just vehicles of pain who live so that others don't suffer from grief should we commit suicide. as we develop a greater sensitivity to the cost of mental illness, policies and social norms will change : some countries now allow for euthanasia for those with chronic and unbearable mental illness. but what's strange about all of this is, even though i'm certain i have the right to kill myself because i'm miserable everyday, i am pulling for you to live, even though you're a stranger on the internet. i have hope for you and i don't even know you. i want you to wait it out, to battle it out, not because you owe me or anyone else, but because i think there might be something better for you in a day or a week or a decade from now. what have you tried so far to get some relief? has anything worked? what can you do that brings you moments of enjoyment? \n",
            "\n",
            "Predicted Sentence : i'not. i. is i is a so. a the people are not the depression. the.. the depression. i'is a that'not a. a. are with much is are't have from the. be'to to i i are a relationship depression to help pain of of depression. i and the social, be the i of are have to this -cs the people people conditions depression conditions conditions. i i is s a, you the the is the i if i'm not that'a same to be.. i'm not and, i'going to the. be. i i if're not patient. the road. i'a to a. you'' t know know what are i'to to know... but be with.. but and i can me to or else else but i i'you is be be to to me. the relationship. depression psychiatrist. or few... i is you done to to far do you treatment.? you you to can you have you you me to. a and \n",
            "\n",
            "Target Sentence : we often ask that question out of habit and rarely out of genuine interest in the answer. it feels unnatural to say anything other than good or fine and we don't expect a different answer than that from anyone else. it's weird that we even ask when you think about it... \n",
            "\n",
            "Predicted Sentence : i'' me i. of the. i i of of feelings. the world. i'like to be it about about the. a. i'' t know to lot thing. the i i else. i's a to i'' about i'you about. t you much good the the the the the the the.. seems good be be be be a. a a a the.. the the the me. the the the the the the the the. i hard good like be be like to a. the it it i you you the the the the the the the the world s a a good good be me like. a. a the the a the the i the the the the the. i the my the the the the the..'like good be be something the a a a a a the the the.. the the the me the the.. the the the the the the the world'''hard like be be be be the a a a a a don't a good good. you the i the the the \n",
            "\n",
            "Target Sentence : as someone said here previously, depression doesn't care who you are, where you are from, what you have or don't have. even if you don't have serious problems, depression makes you feel like you're carrying all the problems of the world. it's true btw, there are people who are disabled, blind, deaf and still be happy, i don't have any of these problems, yet feel shit most of the time, and that makes me feel guilty.. \n",
            "\n",
            "Predicted Sentence : i i i i i i i.'t know. i have. but i'going. i i want to you't know to i i'' t know to feelings with i, worse feel better i're not a the same. the world.'s not that 'w i'many who who not to but.. feeling able. but'' t know to to the things. but but better. people the time. but i'me feel feel.'know'know know feel know people i'''' you you the i you me better better better...'''''' know'you to the you i i '.'''''' about i i. i i i.. i do you have you don'know know know'to to i i i'''''''' i i i. are. i i i '. i i have'don'''know know know know to don'know a with with with,,. like \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hOi-zit_He-"
      },
      "source": [
        "##3b) Seeker post + non-empathetic response as input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4-ZUmug7b5h"
      },
      "source": [
        "#import csv into dataframe\n",
        "data_df = pd.read_csv('drive/MyDrive/data.csv', encoding=\"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIjvUe4P7hKg"
      },
      "source": [
        "#split into train, val and test sets (80-10-10)\n",
        "train_df = data_df.iloc[: int(len(data_df) * 0.8 ) ,:  ]\n",
        "val_df_copy = data_df.iloc[ len(data_df) - int(len(data_df) * 0.2 ) :  ,:  ]\n",
        "val_df = val_df_copy.iloc[ int( len(val_df_copy) * 0.5 ) : , :  ]\n",
        "test_df = val_df_copy.iloc[ : int( len(val_df_copy) * 0.5 ) , :  ]\n",
        "\n",
        "train_df.to_csv( \"train_data.csv\" )\n",
        "val_df.to_csv( \"val_data.csv\" )\n",
        "test_df.to_csv( \"test_data.csv\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt9vEwUE7u3I"
      },
      "source": [
        "def convert_text( en_file , en_comp_file , data_df  ):\n",
        "  with open( en_file , \"w\") as my_output_file:\n",
        "    [ my_output_file.write(\"\".join( row[1].seeker_post + \" SPLIT \" +  row[1].source )+'\\n') for row in  data_df.iterrows() ]\n",
        "    my_output_file.close()\n",
        "\n",
        "  with open( en_comp_file , \"w\") as my_output_file:\n",
        "    [ my_output_file.write(\"\".join( row[1].target)+'\\n') for row in  data_df.iterrows() ]\n",
        "    my_output_file.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiN_nzUf739Q"
      },
      "source": [
        "train_en_file = 'train_en.txt' \n",
        "train_en_comp_file = \"train_en_comp.txt\"\n",
        "convert_text( train_en_file , train_en_comp_file , train_df )\n",
        "\n",
        "\n",
        "val_en_file = 'val_en.txt' \n",
        "val_en_comp_file = \"val_en_comp.txt\"\n",
        "convert_text( val_en_file , val_en_comp_file , val_df )\n",
        "\n",
        "test_en_file = 'test_en.txt' \n",
        "test_en_comp_file = \"test_en_comp.txt\"\n",
        "convert_text( test_en_file , test_en_comp_file , test_df )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScYjHd-w78TM"
      },
      "source": [
        "globalparams ={\n",
        "        \"train_en_file\" : \"/content/train_en.txt\",\n",
        "        \"train_en_comp_file\" : \"/content/train_en_comp.txt\",\n",
        "        \"val_en_file\":\"/content/val_en.txt\" , \n",
        "        \"val_en_comp_file\":\"/content/val_en_comp.txt\",\n",
        "        \"test_en_file\":\"/content/test_en.txt\" , \n",
        "        \"test_en_comp_file\":\"/content/test_en_comp.txt\" }\n",
        "\n",
        "encparams = {\n",
        "        \"tokenizer_path\" : \"tokenizers/\",\n",
        "        \"file_name\" : \"en.text\",\n",
        "        \"min_freq\" : 0 ,\n",
        "        \"max_length\" : 512,\n",
        "        \"num_attn_heads\" : 8,\n",
        "        \"num_hidden_layers\" : 8,\n",
        "        \"hidden_size\" : 512 }\n",
        "\n",
        "decparams = {\n",
        "        \"tokenizer_path\" : \"tokenizers/\",\n",
        "        \"file_name\" : \"en_comp.text\",\n",
        "        \"min_freq\" : 0 ,\n",
        "        \"max_length\" : 120 ,\n",
        "        \"num_attn_heads\" : 8,\n",
        "        \"num_hidden_layers\" : 8,\n",
        "        \"hidden_size\" : 512}\n",
        "\n",
        "modelparams = {\n",
        "        \"batch_size\" : 4 ,\n",
        "        \"num_epochs\" : 1,\n",
        "        \"lr\": 0.000001,\n",
        "        \"model_path\" : \"models/\",\n",
        "        \"model_name\": \"encdec.mdl\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AA6cAOUdVIu",
        "outputId": "096a3350-1aa4-429d-fde2-6750b28e21f3"
      },
      "source": [
        "tokenizer.model_max_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npLMVOOz8Anp"
      },
      "source": [
        "tokenizer.cls_token = \"[CLS]\"\n",
        "tokenizer.unk_token = \"[UNK]\"\n",
        "tokenizer.sep_token = \"[SEP]\"\n",
        "tokenizer.pad_token = \"[PAD]\" \n",
        "tokenizer.bos_token = \"[S]\"\n",
        "tokenizer.mask_token = \"[MASK]\"\n",
        "tokenizer.eos_token =  \"[/S]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK-kFcYy8Eek"
      },
      "source": [
        "tokenizer.do_lower_case = True\n",
        "\n",
        "tokenizer._tokenizer.post_processor = BertProcessing((\"[SEP]\", tokenizer.bos_token_id  ), \n",
        "                                                     (\"[CLS]\", tokenizer.cls_token_id   ),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1byhU27p8LH0"
      },
      "source": [
        "class TranslationDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, inp_file, targ_file, inp_tokenizer, targ_tokenizer, inp_maxlength, targ_maxlength):\n",
        "\n",
        "        self.inp_tokenizer = inp_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.inp_maxlength = inp_maxlength\n",
        "        self.targ_maxlength = targ_maxlength\n",
        "\n",
        "        print(\"Loading and Tokenizing the data ...\")\n",
        "        self.encoded_inp = []\n",
        "        self.encoded_targ = []\n",
        "\n",
        "        # Read the source lines\n",
        "        num_inp_lines = 0\n",
        "        with open(inp_file, \"r\") as ef:\n",
        "            for line in ef:\n",
        "                enc = self.inp_tokenizer.encode(line.strip(), add_special_tokens=True, max_length=self.inp_maxlength , truncation=True)\n",
        "                self.encoded_inp.append(torch.tensor(enc))\n",
        "                num_inp_lines += 1\n",
        "\n",
        "        # read the target lines\n",
        "        num_targ_lines = 0\n",
        "        with open(targ_file, \"r\") as df:\n",
        "            for line in df:\n",
        "                enc = self.targ_tokenizer.encode(line.strip(), add_special_tokens=True, max_length=self.targ_maxlength , truncation=True)\n",
        "                self.encoded_targ.append(torch.tensor(enc))\n",
        "                num_targ_lines += 1\n",
        "\n",
        "        assert (num_inp_lines==num_targ_lines), \"Mismatch in source and target lines\"\n",
        "        print(\"Read\", num_inp_lines, \"lines from source and target files.\")\n",
        "\n",
        "    def __getitem__(self, offset):\n",
        "        src = self.encoded_inp[offset]\n",
        "        trg = self.encoded_targ[offset]\n",
        "\n",
        "        return src, src.shape[0], trg, trg.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_inp)\n",
        "\n",
        "    def collate_function(self, batch):\n",
        "\n",
        "        (inputs, inp_lengths, targets, targ_lengths) = zip(*batch)\n",
        "\n",
        "        padded_inputs = self._collate_helper(inputs, self.inp_tokenizer)\n",
        "        padded_targets = self._collate_helper(targets, self.targ_tokenizer)\n",
        "\n",
        "        max_inp_seq_len = padded_inputs.shape[1]\n",
        "        max_out_seq_len = padded_targets.shape[1]\n",
        "\n",
        "        input_masks = [[1]*l + [0]*(max_inp_seq_len-l) for l in inp_lengths]\n",
        "        target_masks = [[1]*l + [0]*(max_out_seq_len-l) for l in targ_lengths]\n",
        "\n",
        "        input_tensor = padded_inputs.to(torch.int64)\n",
        "        target_tensor = padded_targets.to(torch.int64)\n",
        "        input_masks = torch.Tensor(input_masks)\n",
        "        target_masks = torch.Tensor(target_masks)\n",
        "\n",
        "        return input_tensor, input_masks, target_tensor, target_masks\n",
        "\n",
        "    def _collate_helper(self, examples, tokenizer):\n",
        "        length_of_first = examples[0].size(0)\n",
        "        are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
        "        if are_tensors_same_length:\n",
        "            return torch.stack(examples, dim=0)\n",
        "        else:\n",
        "            if tokenizer._pad_token is None:\n",
        "                raise ValueError(\n",
        "                    \"You are attempting to pad samples but the tokenizer you are using\"\n",
        "                    f\" ({tokenizer.__class__.__name__}) does not have one.\"\n",
        "                )\n",
        "            return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcury8JI8R7p",
        "outputId": "0156282c-7a5b-4581-cea1-b5316bd4697c"
      },
      "source": [
        "# Load the tokenizers\n",
        "en_tokenizer = tokenizer\n",
        "en_complex_tokenizer = tokenizer\n",
        "\n",
        "# Init the dataset\n",
        "train_en_file = globalparams[\"train_en_file\"]\n",
        "train_en_complex_file = globalparams[\"train_en_comp_file\"]\n",
        "val_en_file = globalparams[\"val_en_file\"]\n",
        "val_en_complex_file = globalparams[\"val_en_comp_file\"]\n",
        "test_en_file = globalparams[\"test_en_file\"]\n",
        "test_en_complex_file = globalparams[\"test_en_comp_file\"]\n",
        "\n",
        "enc_maxlength = encparams[\"max_length\"]\n",
        "dec_maxlength = decparams[\"max_length\"]\n",
        "\n",
        "batch_size = modelparams[\"batch_size\"]\n",
        "\n",
        "train_dataset = TranslationDataset( train_en_file, train_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=train_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 986 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsgMDdER8axy",
        "outputId": "236725fd-3cd8-4b8b-95fb-8437a226e491"
      },
      "source": [
        "valid_dataset = TranslationDataset(val_en_file, val_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=valid_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 123 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUTgo6aG8jn2",
        "outputId": "c3676509-3ac9-492f-f2ed-ae237c05ed90"
      },
      "source": [
        "test_dataset = TranslationDataset(test_en_file, test_en_complex_file, en_tokenizer, en_complex_tokenizer, enc_maxlength, dec_maxlength)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, \\\n",
        "                                                drop_last=True, num_workers=1, collate_fn=test_dataset.collate_function)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading and Tokenizing the data ...\n",
            "Read 123 lines from source and target files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GWrkVgE-aVn"
      },
      "source": [
        "x , _ , y , _ = next(iter(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCvXA57o-eIy",
        "outputId": "85cc7d48-a594-46e3-a990-860d5b296838"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWQ20SVH-fHy",
        "outputId": "662bc14e-5d65-4c3e-a560-172d731fb28c"
      },
      "source": [
        "bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rat2EPXNd1IW"
      },
      "source": [
        "bert2bert.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "bert2bert.config.eos_token_id = tokenizer.sep_token_id\n",
        "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
        "bert2bert.config.vocab_size = bert2bert.config.encoder.vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3Vg534d2TY"
      },
      "source": [
        "bert2bert.config.max_length = 120\n",
        "bert2bert.config.min_length = 56\n",
        "bert2bert.config.no_repeat_ngram_size = 3\n",
        "bert2bert.config.early_stopping = True\n",
        "bert2bert.config.length_penalty = 2.0\n",
        "bert2bert.config.num_beams = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdwklPW-h9S",
        "outputId": "d01a117d-4906-4b83-a062-fe0491e37dc0"
      },
      "source": [
        "bert2bert.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoderModel(\n",
              "  (encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bky9V-j_-mAc"
      },
      "source": [
        "#define optimiser and loss function\n",
        "optimizer = optim.Adam( bert2bert.parameters(), lr=modelparams['lr'])\n",
        "criterion = nn.CrossEntropyLoss(ignore_index= tokenizer.pad_token_id)\n",
        "\n",
        "num_train_batches = len(train_dataloader)\n",
        "num_valid_batches = len(valid_dataloader)\n",
        "num_test_batches = len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxSxR8ve-rFL"
      },
      "source": [
        "def compute_loss(predictions, targets):\n",
        "    \"\"\"Compute our custom loss\"\"\"\n",
        "    predictions = predictions[:, :-1, :].contiguous()\n",
        "    targets = targets[:, 1:]\n",
        "\n",
        "    rearranged_output = predictions.view(predictions.shape[0]*predictions.shape[1], -1)\n",
        "    rearranged_target = targets.contiguous().view(-1)\n",
        "\n",
        "    loss = criterion(rearranged_output, rearranged_target)\n",
        "\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXpKVlnr-57D"
      },
      "source": [
        "tr = {'loss': [], 'PPL': []}\n",
        "\n",
        "def train_model():\n",
        "    bert2bert.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(train_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert2bert.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    train_loss = epoch_loss / num_train_batches\n",
        "\n",
        "    # store logs\n",
        "    tr['loss'].append(train_loss)\n",
        "    tr['PPL'].append(math.exp(train_loss))\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hInJ6l_-_Yk"
      },
      "source": [
        "val = {'loss': [], 'PPL': []}\n",
        "\n",
        "def eval_model():\n",
        "    bert2bert.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(valid_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    valid_loss =  epoch_loss / num_valid_batches \n",
        "\n",
        "    # store logs\n",
        "    val['loss'].append(valid_loss)\n",
        "    val['PPL'].append(math.exp(valid_loss))\n",
        "\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8eeKb9_FYr"
      },
      "source": [
        "tst = {'loss': [], 'PPL': []}\n",
        "\n",
        "def test_model():\n",
        "    bert2bert.eval()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "\n",
        "    for i, (en_input, en_masks, de_output, de_masks) in enumerate(test_dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        en_input = en_input.to(device)\n",
        "        de_output = de_output.to(device)\n",
        "        en_masks = en_masks.to(device)\n",
        "        de_masks = de_masks.to(device)\n",
        "\n",
        "        lm_labels = de_output.clone()\n",
        "\n",
        "        out = bert2bert(input_ids=en_input, attention_mask=en_masks,\n",
        "                                        decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "\n",
        "        prediction_scores = out[1]\n",
        "        predictions = F.log_softmax(prediction_scores, dim=2)\n",
        "        loss = compute_loss(predictions, de_output)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    test_loss =  epoch_loss / num_valid_batches \n",
        "\n",
        "    # store logs\n",
        "    tst['loss'].append(test_loss)\n",
        "    tst['PPL'].append(math.exp(test_loss))\n",
        "\n",
        "    print(f'\\t Test Loss: {test_loss:.3f} |  Test PPL: {math.exp(test_loss):7.3f}')\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwz5Z-Xlpci0",
        "outputId": "f251fa19-b8d4-4646-f257-88c7cf22740c"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(bert2bert):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 247,363,386 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOm1WVxZ_Lot",
        "outputId": "692be291-c875-4c9a-9c2f-8e65ca3a9493"
      },
      "source": [
        "# MAIN TRAINING LOOP\n",
        "for epoch in range(10):\n",
        "    print(\"Starting epoch\", epoch+1)\n",
        "    train_model()\n",
        "    eval_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "\tTrain Loss: 6.573 | Train PPL: 715.370\n",
            "\t Val. Loss: 5.982 |  Val. PPL: 396.061\n",
            "Starting epoch 2\n",
            "\tTrain Loss: 5.846 | Train PPL: 345.835\n",
            "\t Val. Loss: 5.541 |  Val. PPL: 254.855\n",
            "Starting epoch 3\n",
            "\tTrain Loss: 5.529 | Train PPL: 251.966\n",
            "\t Val. Loss: 5.240 |  Val. PPL: 188.685\n",
            "Starting epoch 4\n",
            "\tTrain Loss: 5.306 | Train PPL: 201.522\n",
            "\t Val. Loss: 5.053 |  Val. PPL: 156.433\n",
            "Starting epoch 5\n",
            "\tTrain Loss: 5.142 | Train PPL: 171.044\n",
            "\t Val. Loss: 4.924 |  Val. PPL: 137.599\n",
            "Starting epoch 6\n",
            "\tTrain Loss: 5.017 | Train PPL: 150.925\n",
            "\t Val. Loss: 4.831 |  Val. PPL: 125.394\n",
            "Starting epoch 7\n",
            "\tTrain Loss: 4.920 | Train PPL: 137.070\n",
            "\t Val. Loss: 4.758 |  Val. PPL: 116.470\n",
            "Starting epoch 8\n",
            "\tTrain Loss: 4.833 | Train PPL: 125.550\n",
            "\t Val. Loss: 4.699 |  Val. PPL: 109.870\n",
            "Starting epoch 9\n",
            "\tTrain Loss: 4.764 | Train PPL: 117.246\n",
            "\t Val. Loss: 4.644 |  Val. PPL: 103.908\n",
            "Starting epoch 10\n",
            "\tTrain Loss: 4.690 | Train PPL: 108.886\n",
            "\t Val. Loss: 4.604 |  Val. PPL:  99.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "izQz4ABE_QZY",
        "outputId": "88f2fbb9-ffc4-4170-9922-49e351b87693"
      },
      "source": [
        "#plot train and validation PPL logs\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "\n",
        "y1 = tr['PPL']\n",
        "y2 = val['PPL']\n",
        "\n",
        "plt.plot(y1, \"-b\", label=\"Train perplexity\")\n",
        "plt.plot(y2, \"-r\", label=\"Validation perplexity\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.ylim(0, 850)\n",
        "plt.ylabel('Perplexity', fontsize=12)\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.title(\"Train and validation perplexity \\n BERT2BERT - Seeker post + non-empathetic response input\", fontsize = 14)\n",
        "\n",
        "fig.savefig(\"3b-ppl.pdf\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoYs6Nx0_Yiq",
        "outputId": "7362695b-7257-48d7-d079-f836653dfff1"
      },
      "source": [
        "test_loss_3b = test_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Test Loss: 4.512 |  Test PPL:  91.141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JoJA3_5_iZU",
        "outputId": "ba21edee-b20d-49cb-af34-2393eb34384f"
      },
      "source": [
        "print(\"Saving model ..\")\n",
        "save_location = modelparams['model_path']\n",
        "model_name = modelparams['model_name']\n",
        "if not os.path.exists(save_location):\n",
        "    os.makedirs(save_location)\n",
        "save_location = os.path.join(save_location, model_name)\n",
        "torch.save(bert2bert, save_location)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N2Yn9fR_jUo"
      },
      "source": [
        "def generate_sentence(model, iterator):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    pred_trg_pairs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, (en_input, en_masks, de_output, de_masks) in enumerate(iterator):\n",
        "\n",
        "            en_input = en_input.to(device)\n",
        "            de_output = de_output.to(device)\n",
        "            en_masks = en_masks.to(device)\n",
        "            de_masks = de_masks.to(device)\n",
        "\n",
        "            lm_labels = de_output.clone()\n",
        "\n",
        "            out = model(input_ids=en_input, attention_mask=en_masks,\n",
        "                                            decoder_input_ids=de_output, decoder_attention_mask=de_masks, labels=lm_labels)\n",
        "            prediction_scores = out[1]\n",
        "            outputs = torch.argmax( prediction_scores , dim = -1 )\n",
        "            output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "            target_str = tokenizer.batch_decode( de_output , skip_special_tokens=True)\n",
        "\n",
        "            for i_pred , i_trg in zip( output_str , target_str  ):\n",
        "\n",
        "              print( \"Target Sentence : {} \\n\".format( i_trg )  )\n",
        "              print( \"Predicted Sentence : {} \\n\".format( i_pred )  )\n",
        "            \n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1kBV9f1_prg",
        "outputId": "6c987f6f-fb0e-48fc-9f66-c99279b509ea"
      },
      "source": [
        "generate_sentence( bert2bert , test_dataloader )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Sentence : i think that avoiding work to sit at home in your misery is a bad thing. getting out of the house is recommended even if it's something like going to work. obviously do whatever you feel is best but i don't think skipping work is going to help you get any better. for example i could barely get out of bed this morning to go to work but even though i'm here hating it i would alternatively be at home sleeping until 2pm then lay in bed on my phone all day. \n",
            "\n",
            "Predicted Sentence : i'i i you. try in a. the head. a bad thing. i better of the world. a to to i is s a.. to sleep. i i i i want like going to i'' t have it to. going to work me. out more things i me,'' have to of the. way. try out sleep out i i i'm not to myself'' never be able the. out up.. i out the bed bed bed. of. i'' just it feeling the a a a my least sleep a \n",
            "\n",
            "Target Sentence : it is unfair. modern psychology / psychiatry is completely incapable of helping those who are in severe pain with lifelong battles with mental illness. it often feels like we are just vehicles of pain who live so that others don't suffer from grief should we commit suicide. as we develop a greater sensitivity to the cost of mental illness, policies and social norms will change : some countries now allow for euthanasia for those with chronic and unbearable mental illness. but what's strange about all of this is, even though i'm certain i have the right to kill myself because i'm miserable \n",
            "\n",
            "Predicted Sentence : i'a. i. is i. a a. being the people are not the depression. the.. the depression. i'doesn a it'not a. a. are with much is are't have. the. be be to to i i are a life depression to the pain of the depression. but. the health, be the it of are are to the,c. the people people conditions depression conditions conditions conditions i i is s a? you this the this a i i i'm not that'a same to be.. i'm not. \n",
            "\n",
            "Target Sentence : we often ask that question out of habit and rarely out of genuine interest in the answer. it feels unnatural to say anything other than good or fine and we don't expect a different answer than that from anyone else. it's weird that we even ask when you think about it... \n",
            "\n",
            "Predicted Sentence : i'have you you. there the. i i of the feelings. the world. i'like to be it about about the. a. i'' t know to lot thing. that i i else.'s a to i'can for you'you about. t me me lot lot the the the the the world world world hard good be be be be a the a a a the you you the the me me me me the the the the the the the. hard like like be be the you a it a the \n",
            "\n",
            "Target Sentence : as someone said here previously, depression doesn't care who you are, where you are from, what you have or don't have. even if you don't have serious problems, depression makes you feel like you're carrying all the problems of the world. it's true btw, there are people who are disabled, blind, deaf and still be happy, i don't have any of these problems, yet feel shit most of the time, and that makes me feel guilty.. \n",
            "\n",
            "Predicted Sentence : i i i i i i i.'t '. you '. but i'going. i you are to you't know to i i i'' t know to problems with i, me feel better you're not a of same. the same. i's not that 'w i'things who who going to but and, feeling able with but'' t know to to things things. but but i, people the people. i i'you feel better. i'' have a the things the things you i'' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFnsD2AR_c2U"
      },
      "source": [
        "#4. PLOT PERPLEXITY FOR ALL MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YGc2nlnCT9Q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "JByhX7e5Gb41",
        "outputId": "708ff386-fb1c-4a02-fcce-a629f134d76a"
      },
      "source": [
        "labels = ['GRU with attention \\n (no pre-training)', 'GRU with attention \\n (BERT base embeddings)', 'BERT2BERT']\n",
        "non_empathetic_response = [math.exp(test_loss_1a)/8410, math.exp(test_loss_2a)/30522, math.exp(test_loss_3a)/30522] \n",
        "non_empathetic_response_seeker_post = [math.exp(test_loss_1b)/8410, math.exp(test_loss_2b)/30522, math.exp(test_loss_3b)/30522]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "width = 0.25  # the width of the bars\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "#rects1 = ax.bar(x - width/3, non_empathetic_response, width, label='Non-empathetic response')\n",
        "#rects3 = ax.bar(x + width/3, non_empathetic_response_seeker_post, width, label='Seeker post + non-empathetic response')\n",
        "\n",
        "ax.bar(x - width/2, non_empathetic_response, width, label='Non-empathetic response', color='gold')\n",
        "ax.bar(x + width/2, non_empathetic_response_seeker_post, width, label='Seeker post + non-empathetic response',  color='b')\n",
        "\n",
        "\n",
        "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "ax.set_ylabel('Normalised PPL', fontsize= 12)\n",
        "#ax.set_yscale('log')\n",
        "ax.set_title('Normalised test perplexity scores per model', fontsize= 14)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels, fontsize= 12)\n",
        "\n",
        "leg = plt.legend(title=\"Model input:\")\n",
        "leg._legend_box.align = \"left\"\n",
        "\n",
        "fig.savefig('testppl.pdf')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}